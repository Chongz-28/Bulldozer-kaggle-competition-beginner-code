{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blue book bulldozer competition from kaggle. Datasets used here were taken directly from kaggle\n",
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#import the data, both training and validation sets.\n",
    "#df = pd.read_csv(\"TrainAndValid.csv\", low_memory = False)\n",
    "#df.head()\n",
    "#df.info()\n",
    "\n",
    "#reimport data insuring sale date column is passed as a date\n",
    "df = pd.read_csv(\"TrainAndValid.csv\", low_memory = False, parse_dates = [\"saledate\"])\n",
    "df.saledate.dtype #checking the type\n",
    "\n",
    "#sort dataframe by date\n",
    "#good idea to sort date data by date \n",
    "df.sort_values(by = [\"saledate\"], inplace = True,ascending = True) #inplace will sort of \"reassign\"\n",
    "df.saledate.head\n",
    "\n",
    "df_tmp = df.copy() #make copy of df so that original is safe\n",
    "\n",
    "#feature engineering\n",
    "##break down saledate column into day,year,month etc so we convert from timeseries representation\n",
    "df_tmp[\"saleYear\"] = df_tmp.saledate.dt.year\n",
    "df_tmp[\"saleMonth\"] = df_tmp.saledate.dt.month\n",
    "df_tmp[\"saleDay\"] = df_tmp.saledate.dt.day\n",
    "df_tmp[\"saleDayOfWeek\"] = df_tmp.saledate.dt.dayofweek\n",
    "df_tmp[\"saleDayOfYear\"] = df_tmp.saledate.dt.dayofyear\n",
    "\n",
    "#drop actual sale date column\n",
    "df_tmp.drop([\"saledate\"], axis = 1, inplace = True)\n",
    "\n",
    "#viewing our reformed dataframe\n",
    "#df_tmp.head().T\n",
    "len(df_tmp)\n",
    "\n",
    "#Model based EDA, converting our data into numbers\n",
    "##firstly, lets find columns which contain strings\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        print(label)\n",
    "        \n",
    "#turning all the string values into categoricals\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        df_tmp[label] = content.astype(\"category\").cat.as_ordered()\n",
    "\n",
    "df_tmp.info() #we notice that all our string objects are now categorical objects\n",
    "#pandas will now treat categorical values as numerics somehow underthe hood. We have to now take care of the missing values.\n",
    "\n",
    "#Save our current preprocessed dataframe\n",
    "df_tmp.to_csv(\"train_temp.csv\", index = False)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#filling in numerical missing values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)\n",
    "\n",
    "#df_tmp.ModelID\n",
    "\n",
    "#search for actual numeric vars that have missing points\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)\n",
    "\n",
    "#lets fill with median (more robust than mean, not sensitive to outliers)\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            #add binary column which tells us if the data was missing\n",
    "            df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            #fill missing numeric values with median\n",
    "            df_tmp[label] = content.fillna(content.median())\n",
    "\n",
    "#check to see if we still have any columns missing numerics\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label) #does not print out anything so we are sorted.\n",
    "            \n",
    "#filling the categoricals \n",
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        #add a binary column to indicate whether sample had missing value\n",
    "        df_tmp[label+\"_is_missing\"] = pd.isnull(content)\n",
    "        #turn cats into numbers and add +1, because missing values get given value -1, we want that to be 0.\n",
    "        df_tmp[label] = pd.Categorical(content).codes + 1\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------\n",
    "#split the data by saleyear\n",
    "df_val = df_tmp[df_tmp.saleYear == 2012]\n",
    "df_train = df_tmp[df_tmp.saleYear != 2012]\n",
    "\n",
    "len(df_val) , len(df_train)\n",
    "\n",
    "#split data into x and y\n",
    "X_train, y_train = df_train.drop(\"SalePrice\", axis = 1), df_train.SalePrice\n",
    "X_valid, y_valid = df_val.drop(\"SalePrice\", axis = 1), df_val.SalePrice\n",
    "\n",
    "#building and evaluation metric\n",
    "##create an evaluation function that we can use its functionality many times\n",
    "##import some metrics\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error\n",
    "\n",
    "def rmsle(y_test, y_preds):\n",
    "    \"\"\"\n",
    "    calculates root mean squared log error between predictions and true lables\n",
    "    \"\"\"\n",
    "    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n",
    "\n",
    "#create func to eval model on different levels \n",
    "#we expect valuation metrics to be better on the training data than validation (overfit if other way round)\n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_valid)\n",
    "    scores = {\"Traing MAE\": mean_absolute_error(y_train, train_preds),\n",
    "             \"Valid MAE:\": mean_absolute_error(y_valid,val_preds),\n",
    "             \"Training RMSLE\":rmsle(y_train,train_preds),\n",
    "             \"Valid RMSLE\":rmsle(y_valid,val_preds)}\n",
    "    \n",
    "    return scores\n",
    "\n",
    "#model building\n",
    "#we will build on a subset of out data so that we are able to cut on run time and also use part of the data to tune hyperpars\n",
    "#we do this because we have alot of data.\n",
    "#in random forest, we will change max_samples value parameters\n",
    "\n",
    "model = RandomForestRegressor(n_jobs = -1, random_state = 42, max_samples = 10000) #every n_estimator will see the data/patterns of the data 10000 times\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#evaluate performance\n",
    "show_scores(model) #results as expected, we are not overfitting for these samples\n",
    "\n",
    "#Can we imporve these metrics? \n",
    "#Hyperparameter tuning with Randomized search cv. Could improve or worsen our metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#different RandomForestRegressor hyperpars\n",
    "rf_grid = {\"n_estimators\": np.arange(10,100,1000),\n",
    "          \"max_depth\": [None,3,5,10],\n",
    "          \"min_samples_split\": np.arange(2,20,2),\n",
    "          \"min_samples_leaf\": np.arange(1,20,2),\n",
    "          \"max_features\": [0.5,1,\"sqrt\",\"auto\"],\n",
    "          \"max_samples\": [10000]}\n",
    "\n",
    "#instantiate RandomizedSearchCV model\n",
    "rs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs = -1, random_state = 42), param_distributions = rf_grid, cv = 5, n_iter = 5, verbose = True)\n",
    "\n",
    "#fit the randomized search cv model\n",
    "rs_model.fit(X_train, y_train)\n",
    "\n",
    "#find the best model hyperpars\n",
    "rs_model.best_params_\n",
    "show_scores(rs_model) \n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "#test dataset\n",
    "#create function to also preprocess our test dataset same way we did for train and validation\n",
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    performs transformations on df and returns transformed dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    df.saledate.dtype\n",
    "    df.sort_values(by = [\"saledate\"], inplace = True,ascending = True)\n",
    "    df[\"saleYear\"] = df.saledate.dt.year\n",
    "    df[\"saleMonth\"] = df.saledate.dt.month\n",
    "    df[\"saleDay\"] = df.saledate.dt.day\n",
    "    df[\"saleDayOfWeek\"] = df.saledate.dt.dayofweek\n",
    "    df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n",
    "\n",
    "    #drop actual sale date column\n",
    "    df.drop(\"saledate\", axis = 1, inplace = True)\n",
    "    \n",
    "    #fill numeric rows to median\n",
    "    for label, content in df.items():\n",
    "        if pd.api.types.is_numeric_dtype(content):\n",
    "            if pd.isnull(content).sum():\n",
    "                #add binary column which tells us if the data was missing\n",
    "                df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "                #fill missing numeric values with median\n",
    "                df[label] = content.fillna(content.median())\n",
    "    \n",
    "    #fill categorical missing data and turn cats into numbers\n",
    "        if not pd.api.types.is_numeric_dtype(content):\n",
    "            #add a binary column to indicate whether sample had missing value\n",
    "            df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            #turn cats into numbers and add +1, because missing values get given value -1, we want that to be 0.\n",
    "            df[label] = pd.Categorical(content).codes + 1\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "#import test dataset\n",
    "df_test = pd.read_csv(\"Test.csv\",low_memory = False,parse_dates = [\"saledate\"])\n",
    "df_test.head().T\n",
    "\n",
    "#process the test data\n",
    "df_test = preprocess_data(df_test)\n",
    "df_test.head()\n",
    "\n",
    "#make a prediction\n",
    "test_preds = rs_model.predict(df_test)\n",
    "\n",
    "#the above line throws out an error, the shape of xtrain and our test data differs by 1 column.\n",
    "#find the missing column as below\n",
    "\n",
    "set(X_train.columns) - set(df_test.columns)\n",
    "\n",
    "#auctioneerID is missing, we manually adjust df_test to include that missing column, or you could omit it from our train phase data.\n",
    "df_test[\"auctioneerID_is_missing\"] = False\n",
    "df_test.head()\n",
    "\n",
    "#we can now predict as both dataframes (test and train) have the same features\n",
    "test_preds = rs_model.predict(df_test)\n",
    "\n",
    "#format predictions into format that kaggle wants so we can submit and see where we place on the leaderboard\n",
    "df_preds = pd.DataFrame() #create an empty dataframe\n",
    "df_preds[\"SalesID\"] = df_test[\"SalesID\"]\n",
    "df_preds[\"SalesPrice\"] = test_preds\n",
    "df_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
